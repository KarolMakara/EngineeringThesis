\chapter{Background and Related Work}
\label{cha:background}

Placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder placeholder


%---------------------------------------------------------------------------

\section{Containerization}
\label{sec:containerization}

Contenerization is packaging an app along with all necessary runtime stuff like libraries, executables or asets into an object called "container". The main benefits of container are\cite{RedhatContainerization}:
\begin{itemize}
    \item Protable and Flexible -- container can be run on bare metal or virtual machine in cloud regardless of operating system. Only a container runtime software like \href{https://docs.docker.com/engine/}{Docker Engine} or \href{https://containerd.io/}{containerd} is required, which allows to interact with host system.
    \item Lightweight -- container is sharing operating system kernel with hostmachine, there is no need to install separate operating system inside
    \item Isolated -- does not depends on host's environment or infrastructure
    \item Standarized -- \href{https://opencontainers.org/}{Open Container Initiative} standarize runtime, image and distribution specifications
\end{itemize}
A container image is set of files and configuration needed to run a container. It is immutable, only new image can be crated with new changes. Consists of layers. The layer contain one modification made a image. All layers are cachable and can be reused when building an image. The mechanism is really usefull when compiling large application components inside one container\cite{DockerImage}.

%---------------------------------------------------------------------------

\section{Contianer Orchestration}
\label{sec:ContianerOrchestration}

Container orchestration is coordinated deploying, managing, networking, scaling and monitoring containers process. It automates and manages whole container's lifecycle, there is no need to worrying about of deployed app, orchestration software like \href{https://kubernetes.io/}{Kubernetes} will take care of its availability \cite{RedhatContainerization}.

The Kubernetes Authors says: "The name Kubernetes originates from Greek, meaning helmsman or pilot. K8s as an abbreviation results from counting the eight letters between the "K" and the "s"" \cite{KubernetesDocs}. K8s is open-source orchestration platform capable of managing containers \cite{KubernetesDocs}. Key functionalities are \cite{KubernetesDocs}:

\begin{itemize}
    \item Automated rollouts and rollbacks -- updates or downgrades version of deplotyed containers at controller rate, replacing containers incrementally
    \item Automatic bin packing --  allows to specify exact resources needed by container (CPU, Memory) to fit on appropriate node
    \item Batch execution -- possible to create sets of tasks which can be run without manual intervention
    \item Designed for extensibility -- permits to add feautres using custom resource definitions without changing source code
    \item Horizontal scaling -- scales (replicate) app based of its need for resources
    \item IPv4/IPv6 dual-stack -- allocates IPv4 or IPv6 to pods and services
    \item Secret and configuration management -- allows store, manage and update secrets. Containers do not have to be rebuilt to access updated  credentials
    \item Self-healing -- restarts crashed containers or by failure specified by user
    \item Service discovery and load balancing -- advertises a container using DNS name or ip. Loadbalances traffic across all pods in deployment
    \item Storage orchestration -- mounts desired storage like local or shipped by cloud provider and make it available for containers
\end{itemize}
Understanding Kubernetes workflow becomes significantly easier by familiarizing with its architecture, which will be discussed in the following seciton.


%---------------------------------------------------------------------------

\section{Kubernetes Architecture}
\label{sec:k8s_arch}
A Kubernetes cluster is a group of machines that run containers and provide all the necessary services to enable communication between containers within the cluster, as well as access to the cluster from the outside. There are two types of components, a control plane and worker node. Minumum one of each is needed to run a container, but to provide more robus and reliable production cluter is better to use two to three control plane nodes  \cite{KubernetesArch}. 

\begin{figure}[tbh]
    \centering
    \includegraphics[width=1\columnwidth]{images/kubernetes-cluster-architecture.png}
    \caption{Kubernetes Cluster Architecture \cite{KubernetesArch}}
    \label{fig:k8s_arch}
\end{figure}

On figure 2.1 there is graphical representation of kubernetes cluster. Not all of components shown on figure are mandatory for kubernetes to work correctly. Take a look on control plane part, \textit{\nameref{sec:cloudControllerManager}} might not be mandatory, in on-premise configurations where interacting with cloud provider is not needed. On the right side of figure in node representation is \textit{\nameref{sec:kubeProxy}} component, which is not mandatory as some networking plugins can provide own implementation of proxy \cite{KubernetesArch}. This is example of "Designed for extensibility", where Kubernetes can acquire 3rd-party features without changing its source code \cite{KubernetesDocs}.

% \begin{figure}[h!]
%     \centering
%     \includesvg[width=\textwidth]{}
%     \caption{An example image.}
%     \label{fig:example}
% \end{figure}



%---------------------------------------------------------------------------



\subsection{Control Plane}
\label{sec:k8s_cplane}

Control plane is like a brain in Kubernetes cluster. To interact with use kubcetl, asks \textit{\nameref{sec:kubeApiServer}}It is responsible for communication with worker nodes running pods, a smallest unit managed by K8s that has containers inside.

%---------------------------------------------------------------------------

\subsubsection{cloud-controller-manager}
\label{sec:cloudControllerManager}

This component allows connect Kubernetes cluster and interact with cloud provider's API. It is combined with kube-controller-manager as single binary and can be replicated. This is the only component that talks to the cloud provider, separating other components from direct communication with the cloud. When running without cloud envirnoment this component is absent \cite{KubernetesArch}.

%---------------------------------------------------------------------------

\subsubsection{etcd}
\label{sec:etcd}

Etcd is an open source distributed key-value store service often used in distributed systems. It is responsible for maintaining both the current state and its previous version in its persistent memory \cite{KubernetesArch}\cite{Etcd}.

%---------------------------------------------------------------------------

\subsubsection{kube-apiserver}
\label{sec:kubeApiServer}

Exposes Kubernetes API to interact with a cluster. Takes responsibility for handling all requests from components and users. This is the component which answers for cluster administrator requests sent by kubectl \cite{KubernetesArch}.

%---------------------------------------------------------------------------

\subsubsection{kube-controller-manager}
\label{sec:kubeControllerManager}

Component which run controller processes. Its compiled binary consists of multiple controllers. Example controllers are \cite{KubernetesArch}:

\begin{itemize}
    \item Node controller -- observes worker nodes if are up and running
    \item Job controller -- responsible for batch execution jobs
    \item EndpointSlice controller -- connects services with pods
\end{itemize}

More controller names can be found in \href{https://github.com/kubernetes/kubernetes/blob/master/cmd/kube-controller-manager/names/controller_names.go}{kubernetes source code}.

%---------------------------------------------------------------------------

\subsubsection{kube-scheduler}
\label{sec:kubeScheduler}

Takes care of pods which are not assigned to a worker node yet. kube-scheduler is looking for node that meets pod's scheduling requirements and fit a pod on that node. Such a node is called feasible node \cite{KubernetesScheduler}.

%---------------------------------------------------------------------------

\subsection{Nodes}
\label{sec:k8sNodes}
All of below mentioned components run on every node in a cluster. 
%---------------------------------------------------------------------------

\subsubsection{Container runtime}
\label{sec:containerRuntime}

Node's key component, has ability to run, execute commands, manage and delete containers in efficient way \cite{KubernetesArch}. 

%---------------------------------------------------------------------------


\subsubsection{kube-proxy}
\label{sec:kubeProxy}

Create networking rules which allows to communicate with Pods from outside cluster. If available kube-proxy uses operating system packet filtering to create set of rules. It is also able to forward traffic by itself. This component is optional, can be replaced with different one if desired one implements key features. \cite{KubernetesArch}.

%---------------------------------------------------------------------------

\subsubsection{kubelet}
\label{sec:kubelet}

It is responsible for managing containers inside pod on its node. Uses Container Runtime Interface to communicate with containers \cite{KubernetesArch} \cite{KubernetesCRI}.

%---------------------------------------------------------------------------

\subsection{Objects}    
\label{sec:k8s_objects}

\subsubsection{Namespace}
\label{sec:namespace}

The purpose of namespace object is to isolate group of resources like pods, deployments, services etc. in a cluster. It helps to organise cluster into virtual sub areas of working space. If \textit{\nameref{svc}} is created in some custom namespace <service-name>.<namespace-name>.svc.cluster.local DNS entry within cluster is created \cite{KubernetesNamespaces}.

\subsubsection{Pods}
\label{sec:pods}

Pods are the smallest deployable objects in Kubernetes. It contains in one or more containers, which can communicate with each other using localhost interface. Since they share IP address, the can not use the same ports. It is really useful, when our service consist of two apps which are coupled together. For example there is a pod which has two containers, one responsible for compiling a code, second one is creating cache entry from compiled object and uploads to some data storage. It has more sense, as sharing data among containers in a pod is rather easier than on node between pods. Scaling is simpler as replicating one pod instead of two. Moreover communication between apps happends using localhost, in scenario where there are two pods with one container, ClusterIP \textit{\nameref{svc}} is needed. However the most common approach is to run one container per pod, where pod is just managing wrapper for contenerized app. Also rather then creating pod directly it is more common to use workload resource like \textit{\nameref{deployment}} \cite{KubernetesPods}.

\subsubsection{ReplicaSet}
\label{replicaset}

Basically \textit{\nameref{replicaset}} consists of pod template, and runs desired number of pods \cite{KubernetesReplicaSet}.

\subsubsection{Deployment}
\label{deployment}

Deployment is a higher level abstraction over \textit{\nameref{replicaset}}, that manages its lifecycle. It provides more features like rollingback an app, as it keeps history of configurations \cite{KubernetesDeployments}.

\subsubsection{DaemonSet}
\label{daemonset}

Running pods using DaemonSet guarantee that every node will have copy of desirded pod (if resource requirements are met etc.). It has ability to automatically add or remove pods, if number of nodes changes. The typical usege is creating monitoring pod on every node \cite{KubernetesDaemonSet}.

\subsubsection{StatefulSet}
\label{statefulset}

StatefulSet unlike \textit{\nameref{deployment}} is stateful. It saves an identity of each pod and if e.g. some persistent storage is assigned to specific e.g. database pod and it dies, kubernetes will recreate pod on the same node as it was previously \cite{KubernetesStatefulSet}.

\subsubsection{Job}
\label{job}

Runs pod that does one task and exists. Kubernetes will retry execution if pod fails specific number of tries set in its configuration \cite{KubernetesJobs}.

\subsubsection{CronJob}
\label{cronjob}
Behaviours like \textit{\nameref{job}}, but is able to run regularly every given time for tasks like database backups or log rotation \cite{KubernetesCronJob}.

\subsubsection{Service}
\label{svc}

Service exposes an application running inside a cluster by using an enpoint. As a pod is ephemeral resource and its address changes from time to time (e.g. when pod is recreated) it better to create dns name that resolves IP address. Moreover service will not advertise unhealthy pods. Usually service exposes one port per service, but for example web app might expose http and https ports. There are four types of services \cite{KubernetesService}.

\begin{enumerate}
    \item ClusterIP -- makes one pod available to other inside cluster by exposing application using inter-cluter IP address. Although its oriented to be accessible within the cluster, objets like \textit{\nameref{ingress}} or \textit{\nameref{gatewayapi}} can expose service to the outside.
    \item NodePort -- by default allocates port (from range 30000-32767) to publish service on every node's ip. In this scenario every node on specified port acts like a proxy to deployed app.
    \item LoadBalancer -- kubernetes does not provide loadbalancer by default and when creating such a service it interacts with cloud provider to create external service for traffic balancing. Loadbalancer can be installed inside cluster.
    \item ExternalName -- allows pods inside Kubernetes to access external service using defined name rather than using IP address 
\end{enumerate}

LOCAL TRAFFIC POLICY

\subsubsection{Ingress}
\label{ingress}

Ingress is an object that manages outside cluster access to services inside a cluster. It is a single point of entry to route traffic to specified pod based on configuration. This is only high abstract object that specifies routing rules in cluster. Real functionalities are provided by an \textit{\nameref{ingresscontroller}}. Nowadays the development of Ingress is frozen, Kubernetes authors pay attention to its successor a \textit{\nameref{gatewayapi}} \cite{KubernetesIngress}.

\subsubsection{Ingress Controller}
\label{ingresscontroller}

Ingress Controller fulfills an \textit{\nameref{ingress}} and starts serving an application which performs configured rules. Any implementation has its own features, but common functionalities are L4/L7 loadbalancing, host and path based routing, SSL termination. This is the real application that runs in a pod. Ingress Controller have to be installed manually and is not part of Kubernetes, however the container orchestration tool developers maintain \href{https://github.com/kubernetes-sigs/aws-load-balancer-controller#readme}{AWS}, \href{https://github.com/kubernetes/ingress-gce/blob/master/README.md#readme}{GCE}, and \href{https://github.com/kubernetes/ingress-nginx/blob/main/README.md#readme}{nginx} ingress controllers \cite{KubernetesIngress}\cite{KubernetesIngressControllers}.

\subsubsection{Gateway API}
\label{gatewayapi}

The functionalities of Gateway API are so wide, that the Kubernetes authors use term "project". The project mainly focus on L4 and L7 routing in a cluster. It succeeds \textit{\nameref{ingress}}, Load Balancing and service mesh APIs. The Gatewa API resource model is role-oriented \cite{KubernetesGatewayAPI}.

\begin{figure}[tbh]
    \centering
    \includegraphics[width=0.7\columnwidth]{images/gateway-api-resource-model.png}
    \caption{Gateway API roles-oriented resource model \cite{KubernetesGatewayAPI}}
    \label{fig:gatewayApiResourceModel}
\end{figure}

The model focus on 3 separate group of peoples who interact with a cluster on different levels.

On a top of figure~\ref{fig:gatewayApiResourceModel} there are infrastructure providers, who provide GatewayClass resource. They are responsible for the overall multiple clusters infrastructure, rather than ensuring developers can access pods correctly \cite{KubernetesGatewayAPI}. The Gateway API craetors provides clear overview of what GatewayClass: "This resource represents a class of Gateways that can be instantiated.". It defines specific types of loadbalancing implementations and provide clear explenation of capabilities availabe in Kubernetes resource model.  The functionality is similiar to \textit{\nameref{ingress}} \cite{KubernetesGatewayAPI} \cite{KubernetesGatewayClass}. There can be more than one GatewayClasss created. \cite{KubernetesGatewayAPI}. 

Cluter operators are in the middle of figure~\ref{fig:gatewayApiResourceModel}, they make sure that cluster is meets requirements for several users. As maintainers define Gateway resource, some loadbalancing system is provisioned by GatewayClasss. Gateway resource defines specific instance which will handle incomming traffic. Allows to define specific protocol, port or allowed resources route incomming traffic \cite{KubernetesGatewayAPI} \cite{KubernetesGateway}.

End users specified on Gateway API resource model on~\ref{fig:gatewayApiResourceModel} figure are application developers. They focus on serving application to the clients by creating resource named HTTPRoute. The resource defines HTTP routing from defined gateway to end API object like service. GRPCRoute is simmiliar, but operates on different protocol. \cite{KubernetesGatewayAPI} \cite{KubernetesHTTPRoute}.


Gateway API is not an API Gateway. An API Gateway in general is resposible for routing, loadbalancing, information exchange manipulation and much more depending on specific implementation. Gateway API is set of three resources mentioned earlier, which creates a role-oriented Kubernetes service networking model. Creators of Gateway API provide a clear explenation: "Most Gateway API implementations are API Gateways to some extent, but not all API Gateways are Gateway API implementations" \cite{KubernetesGatewayAPI}.


%---------------------------------------------------------------------------



\section{Cluster Networking}
\label{sec:k8s_networking}

Networking is a most important thing in Kubernetes, the whole point is to obtain reliable and robust communication among containers, pods, services, nodes and external systems in a cluter \cite{KubernetesClusterNetworking}. There are four types of network communication: \cite{KubernetesClusterNetworking}:

\begin{enumerate}
    \item container-to-container -- communicates by sharing network resources inside a pod
    \item Pod-to-Pod -- every pod can communicate with any other pod without need to use NAT as every of them has its own IP address \cite{IBMKubernetesNetworking}.
    \item Pod-to-Service -- covered by service type ClusterIP, which provides inter-cluster IP address
    \item External-to-Service -- held by services type NodePort and Loadbalancer, which expose pod to the outside
\end{enumerate}
Kubernetes allocates IP addresses to nodes, services and pods \cite{KubernetesClusterNetworking}:
\begin{itemize}
    \item \textit{\nameref{sec:kubelet}} or \textit{\nameref{sec:cloudControllerManager}}, depending on local or cloud infrastructure allocates IP address for nodes
    \item \textit{\nameref{sec:kubeApiServer}} allocates IP address for services
    \item for allocation of IP address to pod is responsible networking plugin which is an implementation of \textit{\nameref{sec:cni}}
\end{itemize}


%---------------------------------------------------------------------------

\section{Container Network Interface (CNI)}
\label{sec:cni}
CNI is standarized by Cloud Native Computing Foundation set of API rules which defines container networking. Generally speaking CNI is responsible for pod-to-pod communication, which include assigning IP addresses, configuring network interface inside container and routing \cite{IBMKubernetesNetworking}.



%---------------------------------------------------------------------------

\section{Overview of Selected CNI Plugins}
\label{sec:cni_overview}


\begin{table}[h!]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Feature}                  & \textbf{Calico}                                                   & \textbf{Cilium}                                                   & \textbf{Antrea}                                                   \\ \hline
\textbf{CNI Type}                  & L3 Networking (BGP, IPIP, VXLAN)                                  & eBPF-based Networking                                              & Open vSwitch (OVS)                                               \\ \hline
\textbf{Network Policy Support}    & Kubernetes NetworkPolicy + Custom Policies                        & Kubernetes NetworkPolicy + Advanced features with eBPF            & Kubernetes NetworkPolicy + Advanced Policy Features               \\ \hline
\textbf{High Performance}          & High (BGP, VXLAN support)                                         & Very High (eBPF for packet processing)                             & High (Open vSwitch and OVS optimizations)                         \\ \hline
\textbf{Security Features}         & Calico NetworkPolicy, IPsec for Encryption                        & eBPF-based security (L7, L3), DNS filtering, service mesh support & Advanced NetworkPolicy support, Encryption, Secure Networking    \\ \hline
\textbf{Observability}             & Prometheus, Grafana support for metrics                           & Hubble (eBPF-based observability), Prometheus integration          & Prometheus, Flow Monitoring, Open vSwitch Metrics                 \\ \hline
\textbf{Multicluster Support}      & Yes (via Calico GlobalNetworkPolicy)                              & Yes (Cilium MultiCluster)                                          & Yes (Antrea Multicluster, also supports Calico as CNI backend)    \\ \hline
\textbf{Networking Mode}           & Overlay (VXLAN), BGP (for large scale)                            & Direct routing with eBPF (XDP, TC, etc.)                           & Overlay (VXLAN) or Underlay (Direct routing with OVS)             \\ \hline
\textbf{Use Case}                  & Large-scale networks, Security-focused setups                     & Cloud-native apps, Microservices, and observability-heavy setups   & Large-scale Kubernetes deployments with strong network policies  \\ \hline
\textbf{Ease of Setup}             & Moderate (manual configuration for advanced features)            & Moderate (advanced features require configuration)                 & Easy to Moderate (simple setup, advanced features may require tuning) \\ \hline
\end{tabular}
\caption{Comparison of Calico, Cilium, and Antrea CNI Plugins}
\label{tab:cni-comparison}
\end{table}


%---------------------------------------------------------------------------

\section{Related Work}
\label{sec:realted_work}


DoTekst
Na stronie \underline{\texttt{http://kile.sourceforge.net/screenshots.php}} Tekst {\em Kile}, Tekst

Tekst

\begin{itemize}
\item Tekst
\end{itemize}
